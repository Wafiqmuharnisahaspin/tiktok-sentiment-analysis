# -*- coding: utf-8 -*-
"""main-test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YXURmoUrKxOxkBjtPYQU1U7exd762o3C

# Data Preparation
"""

# Commented out IPython magic to ensure Python compatibility.
# import the necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# load dataset
df1= pd.read_csv("https://raw.githubusercontent.com/learning-enisda/tpdm-kelompok13/master/datasets/tiktok_google_play_reviews.csv")

"""# Data Insight"""

# take five samples of data randomly
df1.sample(5)

# get the number of rows and columns
df1.shape

"""Dataset terdirdiri dari :
- 10 Kolom
- 307057 Baris
"""

# displays the column names in the data
df1.columns.values

"""Nama Kolom pada dataset:
- reviewId
- userName
- userImage
- content
- score
- thumbsUpCount
- reviewCreatedVersion
- at
- replyContent
- repliedAt
"""

# prints information about the data
df1.info()

"""Informasi data yang diperoleh :
- Tipe data pada dataset berupa tipe data objek dan integer
- Tidak terdapat missing value
"""

# counting the number of missing values in each column
df1.isnull().sum()

"""Setelah ditampilkan terdapat missing value pada kolom:
- content (4)
- reviewCreatedVersion (89216)
- replyContent (306938)
- repliedAt (306938)
"""

# displaying the missing values
missing_value = df1.isnull().mean()
missing_value

# looking for duplicate data
print(df1.duplicated())

"""# Data Cleaning"""

# drop unnecessary columns
df1.drop(['reviewId', 'userName', 'userImage', 'score', 'thumbsUpCount', 'reviewCreatedVersion', 'at', 'replyContent', 'repliedAt'], inplace=True, axis=1)

# fix missing value
df1 = df1.dropna(subset=['content'])

# show data after cleaning
df1.head()

# change the content label to review
df1 = df1.rename(columns={'content': 'review'})

"""# Machine Learning"""

# import the necessary libraries for model
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

def extract_sentiment(review):
    
    # Create an object of SentimentIntensityAnalyzer class
    sia = SentimentIntensityAnalyzer()
    
    # Use the polarity_scores method to get the sentiment scores
    sentiment = sia.polarity_scores(review)
    
    # Check the compound score, if it's greater than 0, return 'positive'
    if sentiment['compound'] > 0:
        return 'positive'
    
    # Check the compound score, if it's less than 0, return 'negative'
    elif sentiment['compound'] < 0:
        return 'negative'
    
    # If the compound score is 0, return 'neutral'
    else:
        return 'neutral'

# Create a new column 'sentiment' in the dataframe and apply the extract_sentiment function to each review
df1['sentiment'] = df1['review'].apply(extract_sentiment)

# Import train_test_split function from sklearn.model_selection
from sklearn.model_selection import train_test_split

# Assign the review column to the variable X and the sentiment column to the variable y
X = df1['review']
y = df1['sentiment']

# Use the train_test_split function to split the data into training and testing sets
# The test_size parameter is set to 0.2, meaning that 20% of the data will be used for testing
# The random_state parameter is set to 42 for reproducibility
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Import CountVectorizer from sklearn.feature_extraction.text
from sklearn.feature_extraction.text import CountVectorizer

# Create an object of CountVectorizer
cv = CountVectorizer()
# Use the fit_transform method to vectorize the text data in X_train
X_train_vect = cv.fit_transform(X_train)

# Import MultinomialNB from sklearn.naive_bayes
from sklearn.naive_bayes import MultinomialNB

# Create an object of MultinomialNB
clf = MultinomialNB()
# Use the fit method to fit the classifier with the training data
clf.fit(X_train_vect, y_train)

# Use the transform method to vectorize the text data in X_test
X_test_vect = cv.transform(X_test)

# Use the predict method to predict the sentiment of the reviews in X_test
y_pred = clf.predict(X_test_vect)

# Import accuracy_score from sklearn.metrics
from sklearn.metrics import accuracy_score

# Use the accuracy_score function to calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)

# Print the accuracy of the model
print(f"Accuracy: {accuracy:.2f}")

# Create a list of new reviews
new_review = ["I love this app, it's so easy to use and has all the features I need."]

# Use the transform method of the cv object to vectorize the new reviews
new_review_vect = cv.transform(new_review)

# Use the predict method of the clf object to predict the sentiment of the new review
predicted_sentiment = clf.predict(new_review_vect)

# Print the predicted sentiment
print(predicted_sentiment)

# Use the predict_proba method of the clf object to predict the probability of each sentiment class for the new review
predicted_sentiment_proba = clf.predict_proba(new_review_vect)
# Print the predicted sentiment probability
print(predicted_sentiment_proba)